import streamlit as st
import arxiv
from datetime import datetime, timezone
from openai import OpenAI
import time
import urllib3

# ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AI-powered Paper Seeker",
    page_icon="ğŸ”¬",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ”¬ AI-powered Paper Seeker")
st.markdown("**è·¨å­¦ç§‘è®ºæ–‡æœç´¢ï¼ˆAI æ™ºèƒ½ç­›é€‰ï¼‰**")

# é¡¹ç›®ä»‹ç»
with st.expander("ğŸ“– å…³äºæœ¬æœç´¢å™¨", expanded=False):
    st.markdown("""
    ### ğŸ¯ åŠŸèƒ½ä»‹ç»
    æœ¬å·¥å…·ä¸ºå­¦æœ¯ç ”ç©¶äººå‘˜æä¾›æ™ºèƒ½åŒ–çš„è®ºæ–‡æ£€ç´¢æœåŠ¡ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿå‘ç°æœ€æ–°ã€æœ€ç›¸å…³çš„å­¦æœ¯è®ºæ–‡ã€‚
    
    ### ğŸ” æ•°æ®æ¥æº
    - **arXiv.org**: å…¨çƒé¢†å…ˆçš„å¼€æ”¾è·å–é¢„å°æœ¬åº“
    - æ¶µç›–ç‰©ç†å­¦ã€è®¡ç®—æœºç§‘å­¦ã€æ•°å­¦ç­‰å¤šä¸ªå­¦ç§‘é¢†åŸŸ
    - æ¯æ—¥æ›´æ–°ï¼Œå®æ—¶è¿½è¸ªå­¦æœ¯å‰æ²¿
    
    ### ğŸ¤– æ™ºèƒ½åˆ†æ
    - **DeepSeek V3 API**: é‡‡ç”¨ DeepSeek æœ€æ–°çš„å¤§è¯­è¨€æ¨¡å‹ API
    - æ™ºèƒ½ç†è§£è®ºæ–‡å†…å®¹ï¼Œç²¾å‡†åˆ¤æ–­ç ”ç©¶æ–¹å‘ç›¸å…³æ€§
    - è‡ªåŠ¨ç”Ÿæˆä¸­æ–‡æ‘˜è¦ï¼Œå¿«é€Ÿäº†è§£è®ºæ–‡æ ¸å¿ƒå†…å®¹

    """)

st.divider()

# å­¦ç§‘é¢†åŸŸé…ç½®
DISCIPLINES = {
    "å…‰å­¦": {
        "icon": "ğŸ”¬",
        "arxiv_categories": ["physics.optics", "eess.IV", "physics.app-ph", "cond-mat.mtrl-sci", "quant-ph"],
        "topics": {
            "éçº¿æ€§å…‰å­¦": {
                "keywords": ["nonlinear", "nonlinear optics", "SHG", "THG", "FWM", "frequency conversion"],
                "description": "éçº¿æ€§å…‰å­¦æ•ˆåº”ã€é¢‘ç‡è½¬æ¢ã€å’Œé¢‘/å·®é¢‘ç­‰"
            },
            "è¶…å¿«å…‰å­¦": {
                "keywords": ["ultrafast", "femtosecond", "picosecond", "attosecond", "pulse"],
                "description": "é£ç§’/çš®ç§’æ¿€å…‰ã€è¶…çŸ­è„‰å†²æŠ€æœ¯"
            },
            "ç´«å¤–æ¿€å…‰": {
                "keywords": ["ultraviolet", "UV laser", "deep-UV", "DUV"],
                "description": "ç´«å¤–/æ·±ç´«å¤–æ¿€å…‰æŠ€æœ¯"
            },
            "é‡å­å…‰å­¦": {
                "keywords": ["quantum optics", "quantum entanglement", "single photon", "quantum state"],
                "description": "é‡å­çº ç¼ ã€å•å…‰å­æºã€é‡å­æ€æ“æ§"
            },
            "å…‰å­¦é¢‘ç‡æ¢³": {
                "keywords": ["optical frequency comb", "frequency comb", "mode-locked", "comb"],
                "description": "å…‰é¢‘æ¢³ã€é”æ¨¡æ¿€å…‰"
            },
            "å…‰çº¤æ¿€å…‰": {
                "keywords": ["fiber laser", "fiber optics", "optical fiber"],
                "description": "å…‰çº¤æ¿€å…‰å™¨ã€å…‰çº¤å…‰å­¦"
            },
            "è¶…è¿ç»­è°±": {
                "keywords": ["supercontinuum", "SC generation", "broadband"],
                "description": "è¶…è¿ç»­è°±äº§ç”Ÿã€å®½å¸¦å…‰æº"
            },
            "å¤ªèµ«å…¹å…‰å­¦": {
                "keywords": ["terahertz", "THz", "terahertz generation"],
                "description": "å¤ªèµ«å…¹äº§ç”Ÿä¸åº”ç”¨"
            },
            "å…‰å‚é‡è¿‡ç¨‹": {
                "keywords": ["OPO", "OPA", "optical parametric", "parametric amplifier"],
                "description": "å…‰å‚é‡æŒ¯è¡å™¨/æ”¾å¤§å™¨"
            },
            "é«˜æ¬¡è°æ³¢": {
                "keywords": ["high harmonic generation", "HHG", "attosecond pulse"],
                "description": "é«˜æ¬¡è°æ³¢äº§ç”Ÿã€é˜¿ç§’è„‰å†²"
            }
        }
    },
    "è®¡ç®—æœºç§‘å­¦": {
        "icon": "ğŸ’»",
        "arxiv_categories": ["cs.AI", "cs.LG", "cs.CV", "cs.CL", "cs.NE", "stat.ML"],
        "topics": {
            "äººå·¥æ™ºèƒ½": {
                "keywords": ["artificial intelligence", "AI", "machine intelligence", "intelligent systems"],
                "description": "é€šç”¨äººå·¥æ™ºèƒ½ã€æ™ºèƒ½ç³»ç»Ÿ"
            },
            "æœºå™¨å­¦ä¹ ": {
                "keywords": ["machine learning", "deep learning", "neural network", "CNN", "RNN", "transformer"],
                "description": "æ·±åº¦å­¦ä¹ ã€ç¥ç»ç½‘ç»œã€æ¨¡å‹è®­ç»ƒ"
            },
            "è®¡ç®—æœºè§†è§‰": {
                "keywords": ["computer vision", "image processing", "object detection", "segmentation", "visual recognition"],
                "description": "å›¾åƒè¯†åˆ«ã€ç›®æ ‡æ£€æµ‹ã€å›¾åƒåˆ†å‰²"
            },
            "è‡ªç„¶è¯­è¨€å¤„ç†": {
                "keywords": ["natural language processing", "NLP", "language model", "LLM", "GPT", "BERT", "text generation"],
                "description": "è¯­è¨€æ¨¡å‹ã€æ–‡æœ¬ç”Ÿæˆã€å¯¹è¯ç³»ç»Ÿ"
            },
            "å¼ºåŒ–å­¦ä¹ ": {
                "keywords": ["reinforcement learning", "RL", "Q-learning", "policy gradient", "deep RL"],
                "description": "å¼ºåŒ–å­¦ä¹ ã€ç­–ç•¥ä¼˜åŒ–ã€æ™ºèƒ½å†³ç­–"
            },
            "ç”Ÿæˆæ¨¡å‹": {
                "keywords": ["generative model", "GAN", "VAE", "diffusion model", "stable diffusion", "image generation"],
                "description": "ç”Ÿæˆå¯¹æŠ—ç½‘ç»œã€æ‰©æ•£æ¨¡å‹ã€å›¾åƒç”Ÿæˆ"
            },
            "å¤šæ¨¡æ€å­¦ä¹ ": {
                "keywords": ["multimodal", "vision-language", "CLIP", "cross-modal", "audio-visual"],
                "description": "è§†è§‰-è¯­è¨€ã€è·¨æ¨¡æ€å­¦ä¹ "
            },
            "å›¾ç¥ç»ç½‘ç»œ": {
                "keywords": ["graph neural network", "GNN", "graph learning", "node classification"],
                "description": "å›¾ç¥ç»ç½‘ç»œã€å›¾è¡¨ç¤ºå­¦ä¹ "
            },
            "è”é‚¦å­¦ä¹ ": {
                "keywords": ["federated learning", "distributed learning", "privacy-preserving"],
                "description": "è”é‚¦å­¦ä¹ ã€éšç§ä¿æŠ¤å­¦ä¹ "
            },
            "AIå®‰å…¨": {
                "keywords": ["adversarial", "robust", "trustworthy AI", "AI safety", "explainable AI"],
                "description": "å¯¹æŠ—æ”»å‡»ã€æ¨¡å‹é²æ£’æ€§ã€å¯è§£é‡ŠAI"
            }
        }
    }
}

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("âš™ï¸ æœç´¢è®¾ç½®")
    
    # å­¦ç§‘é¢†åŸŸé€‰æ‹©
    st.subheader("ğŸ“š å­¦ç§‘é¢†åŸŸ")
    selected_discipline = st.selectbox(
        "é€‰æ‹©å­¦ç§‘é¢†åŸŸ",
        options=list(DISCIPLINES.keys()),
        format_func=lambda x: f"{DISCIPLINES[x]['icon']} {x}",
        help="é€‰æ‹©æ‚¨æ„Ÿå…´è¶£çš„å­¦ç§‘é¢†åŸŸ"
    )
    
    st.divider()
    
    # æ ¹æ®å­¦ç§‘æ˜¾ç¤ºç ”ç©¶æ–¹å‘
    st.subheader("ğŸ” ç ”ç©¶æ–¹å‘")
    available_topics = DISCIPLINES[selected_discipline]["topics"]
    selected_topics = st.multiselect(
        f"é€‰æ‹©{selected_discipline}ç ”ç©¶æ–¹å‘",
        options=list(available_topics.keys()),
        default=[list(available_topics.keys())[0]],
        help="å¯å¤šé€‰ï¼Œç³»ç»Ÿä¼šæ ¹æ®æ‚¨çš„é€‰æ‹©æ™ºèƒ½ç­›é€‰è®ºæ–‡"
    )
    
    # æ˜¾ç¤ºé€‰ä¸­æ–¹å‘çš„æè¿°
    if selected_topics:
        with st.expander("ğŸ“– æŸ¥çœ‹é€‰ä¸­æ–¹å‘è¯´æ˜"):
            for topic in selected_topics:
                st.caption(f"**{topic}**: {available_topics[topic]['description']}")
    
    st.divider()
    
    # æ—¶é—´èŒƒå›´é€‰æ‹©
    days_range = st.slider(
        "ğŸ“… æ—¶é—´èŒƒå›´ï¼ˆå¤©ï¼‰",
        min_value=1,
        max_value=30,
        value=7,
        help="æœç´¢è¿‡å» N å¤©å†…å‘å¸ƒçš„è®ºæ–‡"
    )
    
    # æœ€å¤§ç»“æœæ•°
    max_results = st.number_input(
        "ğŸ“Š æœ€å¤§æœç´¢æ•°é‡",
        min_value=10,
        max_value=500,
        value=100,
        step=10,
        help="ä» arXiv è·å–çš„æœ€å¤§è®ºæ–‡æ•°é‡"
    )
    
    st.divider()
    st.caption("ğŸ’¡ æç¤ºï¼šæœç´¢æ•°é‡è¶Šå¤šï¼Œè€—æ—¶è¶Šé•¿")

# åˆå§‹åŒ– DeepSeek API
@st.cache_resource
def init_deepseek():
    return OpenAI(
        api_key="sk-7b13af61c56140dd80595921a087bd27",
        base_url="https://api.deepseek.com",
        timeout=30.0,  # è®¾ç½® 30 ç§’è¶…æ—¶
        max_retries=2   # æœ€å¤šé‡è¯• 2 æ¬¡
    )

client_ai = init_deepseek()

# ç”Ÿæˆä¸­æ–‡æ‘˜è¦ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
def generate_summary(title, abstract, max_attempts=3):
    for attempt in range(max_attempts):
        try:
            response = client_ai.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå…‰å­¦é¢†åŸŸçš„ä¸“å®¶ã€‚è¯·ç”¨ä¸­æ–‡ç®€æ˜æ‰¼è¦åœ°æ€»ç»“è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹å’Œåˆ›æ–°ç‚¹ã€‚"},
                    {"role": "user", "content": f"è®ºæ–‡æ ‡é¢˜ï¼š{title}\n\næ‘˜è¦ï¼š{abstract}\n\nè¯·ç”¨2-3å¥è¯æ€»ç»“è¿™ç¯‡è®ºæ–‡çš„æ ¸å¿ƒå†…å®¹ï¼š"}
                ],
                max_tokens=200,
                temperature=0.3
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt < max_attempts - 1:
                time.sleep(2)  # ç­‰å¾… 2 ç§’åé‡è¯•
                continue
            return f"æ‘˜è¦ç”Ÿæˆå¤±è´¥ï¼ˆå·²é‡è¯• {max_attempts} æ¬¡ï¼‰ï¼š{str(e)[:100]}"

# åˆ¤æ–­æ˜¯å¦ç›¸å…³å¹¶æ ‡æ³¨å…·ä½“æ–¹å‘ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
def is_relevant_with_tags(title, abstract, topics_list, max_attempts=3):
    # æ„å»ºåŠ¨æ€çš„åˆ¤æ–­æç¤ºè¯
    topics_desc = "ã€".join(topics_list)
    
    for attempt in range(max_attempts):
        try:
            response = client_ai.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯é¢†åŸŸçš„ä¸“å®¶åŠ©æ‰‹ã€‚è¯·åˆ¤æ–­è®ºæ–‡ä¸å“ªäº›ç ”ç©¶æ–¹å‘ç›¸å…³ã€‚"},
                    {"role": "user", "content": f"è®ºæ–‡æ ‡é¢˜ï¼š{title}\n\næ‘˜è¦ï¼š{abstract}\n\nå€™é€‰ç ”ç©¶æ–¹å‘ï¼š{topics_desc}\n\nè¯·åˆ¤æ–­è¿™ç¯‡è®ºæ–‡ä¸å“ªäº›ç ”ç©¶æ–¹å‘ç›¸å…³ã€‚å¦‚æœç›¸å…³ï¼Œè¯·åˆ—å‡ºå…·ä½“çš„æ–¹å‘åç§°ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰ï¼›å¦‚æœéƒ½ä¸ç›¸å…³ï¼Œè¯·å›ç­”'æ— å…³'ã€‚"}
                ],
                max_tokens=50,
                temperature=0.1
            )
            answer = response.choices[0].message.content.strip()
            
            # åˆ¤æ–­æ˜¯å¦ç›¸å…³
            if "æ— å…³" in answer or "ä¸ç›¸å…³" in answer or answer.lower() == "none":
                return False, []
            
            # æå–ç›¸å…³çš„å…·ä½“æ–¹å‘
            related_topics = []
            for topic in topics_list:
                if topic in answer:
                    related_topics.append(topic)
            
            # å¦‚æœæœ‰åŒ¹é…çš„æ–¹å‘ï¼Œè¿”å› True å’Œæ–¹å‘åˆ—è¡¨
            if related_topics:
                return True, related_topics
            else:
                # å¦‚æœæ²¡æœ‰æ˜ç¡®åŒ¹é…ä½†å›ç­”ä¸æ˜¯"æ— å…³"ï¼Œå¯èƒ½æ˜¯ç›¸å…³çš„ï¼Œè¿”å›æ‰€æœ‰å€™é€‰æ–¹å‘
                return True, [topics_list[0]]  # é»˜è®¤è¿”å›ç¬¬ä¸€ä¸ª
                
        except Exception as e:
            if attempt < max_attempts - 1:
                time.sleep(2)  # ç­‰å¾… 2 ç§’åé‡è¯•
                continue
            st.warning(f"DeepSeek åˆ¤æ–­å¤±è´¥ï¼ˆå·²é‡è¯• {max_attempts} æ¬¡ï¼‰ï¼š{str(e)[:100]}")
            return False, []

# å¼€å§‹æœç´¢æŒ‰é’®
if st.button("ğŸš€ å¼€å§‹æœç´¢", type="primary"):
    # æ£€æŸ¥æ˜¯å¦é€‰æ‹©äº†ç ”ç©¶æ–¹å‘
    if not selected_topics:
        st.error("âŒ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç ”ç©¶æ–¹å‘ï¼")
        st.stop()
    
    # è·å–å½“å‰å­¦ç§‘çš„é…ç½®
    discipline_config = DISCIPLINES[selected_discipline]
    available_topics = discipline_config["topics"]
    
    # æ ¹æ®é€‰æ‹©çš„ç ”ç©¶æ–¹å‘æ„å»ºæœç´¢å…³é”®è¯
    all_keywords = []
    for topic in selected_topics:
        all_keywords.extend(available_topics[topic]["keywords"])
    
    # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ˆç”¨ OR è¿æ¥æ‰€æœ‰å…³é”®è¯ï¼‰
    keyword_query = " OR ".join([f'"{kw}"' if " " in kw else kw for kw in all_keywords])
    
    # æ ¹æ®å­¦ç§‘æ„å»º arXiv åˆ†ç±»æŸ¥è¯¢
    category_query = " OR ".join([f"cat:{cat}" for cat in discipline_config["arxiv_categories"]])
    full_query = f"({category_query}) AND ({keyword_query})"
    
    # é…ç½® arXiv å®¢æˆ·ç«¯
    client = arxiv.Client(page_size=10, delay_seconds=3, num_retries=5)
    search = arxiv.Search(
        query=full_query,
        max_results=max_results,  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å€¼
        sort_by=arxiv.SortCriterion.SubmittedDate
    )
    
    today = datetime.now(timezone.utc)
    
    # è¿›åº¦æ˜¾ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    count = 0
    filtered_count = 0
    relevant_papers = []
    
    try:
        results_list = list(client.results(search))
        total = len(results_list)
        
        for idx, result in enumerate(results_list):
            count += 1
            time_diff = (today - result.published).days
            
            # æ›´æ–°è¿›åº¦
            progress_bar.progress((idx + 1) / total)
            status_text.text(f"æ­£åœ¨æ£€æŸ¥ç¬¬ {count} ç¯‡è®ºæ–‡... ({time_diff} å¤©å‰)")
            
            if time_diff > days_range:  # ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„æ—¶é—´èŒƒå›´
                continue
            
            filtered_count += 1
            
            # åˆ¤æ–­ç›¸å…³æ€§å¹¶è·å–å…·ä½“ç›¸å…³æ–¹å‘
            is_related, related_topics = is_relevant_with_tags(result.title, result.summary, selected_topics)
            
            if is_related:
                # ç”Ÿæˆä¸­æ–‡æ‘˜è¦
                summary_cn = generate_summary(result.title, result.summary)
                
                relevant_papers.append({
                    'title': result.title,
                    'pdf_url': result.pdf_url,
                    'published': result.published,
                    'summary': summary_cn,
                    'related_topics': related_topics  # ä¿å­˜ç›¸å…³çš„å…·ä½“æ–¹å‘
                })
            
            time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        progress_bar.empty()
        status_text.empty()
        
        # æ˜¾ç¤ºç»“æœ
        st.success(f"âœ… æœç´¢å®Œæˆï¼å…±æ£€æŸ¥ {count} ç¯‡è®ºæ–‡ï¼Œ{filtered_count} ç¯‡åœ¨æ—¶é—´èŒƒå›´å†…ï¼Œæ‰¾åˆ° {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡ã€‚")
        
        if relevant_papers:
            st.markdown("---")
            st.header(f"ğŸ“š æ‰¾åˆ° {len(relevant_papers)} ç¯‡ç›¸å…³è®ºæ–‡")
            
            for i, paper in enumerate(relevant_papers, 1):
                with st.expander(f"**{i}. {paper['title']}**", expanded=(i==1)):
                    st.markdown(f"**ğŸ“… å‘å¸ƒæ—¶é—´ï¼š** {paper['published'].strftime('%Y-%m-%d')}")
                    
                    # æ˜¾ç¤º AI åˆ¤å®šçš„ç›¸å…³æ–¹å‘æ ‡ç­¾
                    if paper.get('related_topics'):
                        tags_html = " ".join([f"<span style='background-color: #e8f4f8; padding: 4px 12px; border-radius: 12px; margin-right: 8px; font-size: 14px;'>ğŸ·ï¸ {topic}</span>" for topic in paper['related_topics']])
                        st.markdown(f" {tags_html}", unsafe_allow_html=True)
                    
                    st.markdown(f"**ğŸ”— PDF é“¾æ¥ï¼š** [{paper['pdf_url']}]({paper['pdf_url']})")
                    st.markdown("**ğŸ“ AI ç”Ÿæˆæ‘˜è¦ï¼ˆä¸­æ–‡ï¼‰ï¼š**")
                    st.info(paper['summary'])
        else:
            st.warning("æœªæ‰¾åˆ°ç›¸å…³è®ºæ–‡ã€‚")
    
    except Exception as e:
        st.error(f"âŒ æœç´¢å‡ºé”™ï¼š{e}")
        st.info("**å¯èƒ½çš„è§£å†³æ–¹æ¡ˆï¼š**\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. æ£€æŸ¥ DeepSeek API Key æ˜¯å¦æœ‰æ•ˆ\n3. ç¨åé‡è¯•")
else:
    # æ˜¾ç¤ºå½“å‰è®¾ç½®
    if selected_topics:
        topics_display = "ã€".join(selected_topics)
        st.info(f"ğŸ‘† ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹æœç´¢{selected_discipline}è®ºæ–‡\n\n**å½“å‰è®¾ç½®ï¼š**\n- å­¦ç§‘é¢†åŸŸï¼š{DISCIPLINES[selected_discipline]['icon']} {selected_discipline}\n- ç ”ç©¶æ–¹å‘ï¼š{topics_display}\n- æ—¶é—´èŒƒå›´ï¼šè¿‡å» **{days_range}** å¤©\n- æœ€å¤šæ£€ç´¢ï¼š**{max_results}** ç¯‡")
    else:
        st.warning("âš ï¸ è¯·åœ¨å·¦ä¾§ä¾§è¾¹æ é€‰æ‹©è‡³å°‘ä¸€ä¸ªç ”ç©¶æ–¹å‘")
